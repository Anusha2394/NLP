# -*- coding: utf-8 -*-
"""Anusha_kasa_naivebayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BRLSDsDepGR3g0zOJ7brKS7SLx4bPFRn
"""

import pandas as pd

txt = open("/content/all_sentiment_shuffled.rtf").read()

txt

pip install striprtf

from striprtf.striprtf import rtf_to_text

sample_text =open("/content/all_sentiment_shuffled.rtf").read()
text = rtf_to_text(sample_text)

text

from sklearn.feature_extraction.text import CountVectorizer

import nltk
nltk.download("popular")

from nltk.tokenize import sent_tokenize

data=sent_tokenize(text)
data



import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer

ps = PorterStemmer()
wordnet=WordNetLemmatizer()
corpus = []
for i in range(len(data)):
    review = re.sub('[^a-zA-Z]', ' ', data[i])
    review = review.lower()
    review = review.split()
    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]
    review = ' '.join(review)
    corpus.append(review)

corpus

import matplotlib.pyplot as plt
plt.figure(figsize=(20, 20))

cts=nltk.FreqDist(corpus)
cts.plot(100)

pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()

pip install get-variable-name



polarity_list = []

for sent in corpus:
    print(f'For the sentence "{sent}"')
    polarity = sia.polarity_scores(sent)
    sentiment_dict = sia.polarity_scores(sent) 

    print("sentence was rated as ", sentiment_dict['neg']*100, "% Negative") 
    print("sentence was rated as ", sentiment_dict['neu']*100, "% Neutral") 
    print("sentence was rated as ", sentiment_dict['pos']*100, "% Positive") 
    print("Sentence Overall Rated As", end = " ") 
    # decide sentiment as positive, negative and neutral 
    if sentiment_dict['compound'] >= 0.05 : 
        print("Positive") 
        polarity_list.append(1)
        
  
    elif sentiment_dict['compound'] <= - 0.05 : 
        print("Negative")
        polarity_list.append(-1)
        
  
    else : 
        print("Neutral") 
        polarity_list.append(0)
    print("--------")
print(polarity_list)

df=pd.DataFrame({'Sentence':corpus, 'Polarity':polarity_list})

df.head()

df.shape

import seaborn as sns

sns.countplot(df['Polarity'])





X = df['Sentence']
y = df['Polarity']

from sklearn.model_selection import train_test_split,GridSearchCV

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

from sklearn.naive_bayes import MultinomialNB

model = MultinomialNB()

vect = CountVectorizer()

vect.fit(X_train)

X_train_transform= vect.transform(X_train)

X_train_transform

X_test_transform= vect.transform(X_test)

X_test_transform

model.fit(X_train_transform, y_train)

y_pred = model.predict(X_test_transform)

y_pred

from sklearn import metrics

metrics.accuracy_score(y_test, y_pred)

tuned_parameters = {
    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],
    'tfidf__use_idf': (True, False),
    'tfidf__norm': ('l1', 'l2'),
    'clf__alpha': [1, 1e-1, 1e-2]
}

alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
p_grid_NB = {'alpha': alphas, 'fit_prior' : [True, False], 'class_prior ' : [None, [.1,.9],[.2, .8]]}


grid = GridSearchCV(estimator = model, param_grid = p_grid_NB, scoring = 'roc_auc', cv = 5)
grid.fit(X_train_transform, y_train)

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import sklearn.metrics as metrics

X_transform= vect.transform(X)

cv = KFold(n_splits=10, random_state=1, shuffle=True)
scores = cross_val_score(model, X_transform, y, scoring='accuracy', cv=cv, n_jobs=-1)
print(classification_report(y_test,y_pred))
cm = confusion_matrix(y_test, y_pred)
cmd = ConfusionMatrixDisplay(cm, display_labels=['Negetive','Neutral','Positive'])
cmd.plot()

print(scores)
print(scores.mean())

